{"version":3,"sources":["../../../lib/compiler/tokenizer.js"],"names":["tokens","matchPattern","require","Text","getTopLevelTokens","Object","keys","map","key","filter","token","priority","sort","a","b","removeExtraCloses","input","remove","Set","closeSubject","opens","closes","expectedSubjects","forEach","index","tokenType","startsWith","push","subject","path","test","raw","expectedSubject","pop","add","matches","match","i","length","tok","m","diff","console","warn","output","has","tokenizer","topLevelTokens","cursor","lastBreak","slice","found","text","escapedText","Tok","module","exports"],"mappings":"AAAA;;AAEA,MAAM;AAAEA,EAAAA,MAAF;AAAUC,EAAAA;AAAV,IAA2BC,OAAO,CAAC,UAAD,CAAxC;;AAEA,MAAM;AAAEC,EAAAA;AAAF,IAAWH,MAAjB;;AAEA,SAASI,iBAAT,GAA6B;AAC3B,SAAOC,MAAM,CAACC,IAAP,CAAYN,MAAZ,EACJO,GADI,CACAC,GAAG,IAAIR,MAAM,CAACQ,GAAD,CADb,EAEJC,MAFI,CAEGC,KAAK,IAAIA,KAAK,CAACC,QAAN,GAAiB,CAF7B,EAGJC,IAHI,CAGC,CAACC,CAAD,EAAIC,CAAJ,KAAUD,CAAC,CAACF,QAAF,GAAaG,CAAC,CAACH,QAH1B,CAAP;AAID;;AAED,SAASI,iBAAT,CAA2BC,KAA3B,EAAkC;AAChC,QAAMC,MAAM,GAAG,IAAIC,GAAJ,EAAf;AACA,QAAMC,YAAY,GAAG,4BAArB;AAEA,MAAIC,KAAK,GAAG,CAAZ;AACA,MAAIC,MAAM,GAAG,CAAb;AAEA,QAAMC,gBAAgB,GAAG,EAAzB,CAPgC,CAQhC;;AACAN,EAAAA,KAAK,CAACO,OAAN,CAAc,CAACb,KAAD,EAAQc,KAAR,KAAkB;AAC9B,QAAId,KAAK,CAACe,SAAN,CAAgBC,UAAhB,CAA2B,MAA3B,CAAJ,EAAwC;AACtCN,MAAAA,KAAK,IAAI,CAAT;AAEAE,MAAAA,gBAAgB,CAACK,IAAjB,CACGjB,KAAK,CAACkB,OAAN,IAAiBlB,KAAK,CAACkB,OAAN,CAAcC,IAAhC,IACCnB,KAAK,CAACoB,IAAN,KAAepB,KAAK,CAACoB,IAAN,CAAWC,GAAX,IAAkBrB,KAAK,CAACoB,IAAN,CAAWD,IAA5C,CAFH;AAID,KAPD,MAOO,IAAInB,KAAK,CAACe,SAAN,KAAoB,OAAxB,EAAiC;AACtCJ,MAAAA,MAAM,IAAI,CAAV;AAEA,YAAMW,eAAe,GAAGV,gBAAgB,CAACW,GAAjB,EAAxB;;AAEA,UAAI,CAACD,eAAL,EAAsB;AACpBf,QAAAA,MAAM,CAACiB,GAAP,CAAWxB,KAAX;AACD,OAFD,MAEO;AACL,cAAMyB,OAAO,GAAGzB,KAAK,CAACqB,GAAN,CAAUK,KAAV,CAAgBjB,YAAhB,CAAhB;;AACA,YAAIgB,OAAO,IAAI,CAACH,eAAe,CAACN,UAAhB,CAA2BS,OAAO,CAAC,CAAD,CAAlC,CAAhB,EAAwD;AACtDlB,UAAAA,MAAM,CAACiB,GAAP,CAAWxB,KAAX;AACAY,UAAAA,gBAAgB,CAACK,IAAjB,CAAsBK,eAAtB;AACD,SAHD,MAGO;AACL;AACA;AACA,eAAK,IAAIK,CAAC,GAAGb,KAAK,GAAG,CAArB,EAAwBa,CAAC,GAAGrB,KAAK,CAACsB,MAAlC,EAA0CD,CAAC,IAAI,CAA/C,EAAkD;AAChD,kBAAME,GAAG,GAAGvB,KAAK,CAACqB,CAAD,CAAjB;;AACA,gBAAIE,GAAG,CAACd,SAAJ,CAAcC,UAAd,CAAyB,MAAzB,CAAJ,EAAsC;AACpC;AACD;;AACD,gBAAIa,GAAG,CAACd,SAAJ,KAAkB,OAAtB,EAA+B;AAC7B,oBAAMe,CAAC,GAAGD,GAAG,CAACR,GAAJ,CAAQK,KAAR,CAAcjB,YAAd,CAAV;;AACA,kBAAIqB,CAAC,IAAIA,CAAC,CAAC,CAAD,CAAD,KAASR,eAAlB,EAAmC;AACjC;AACAf,gBAAAA,MAAM,CAACiB,GAAP,CAAWxB,KAAX;AACAY,gBAAAA,gBAAgB,CAACK,IAAjB,CAAsBK,eAAtB;AACA;AACD;AACF;AACF;AACF;AACF;AACF;AACF,GAzCD;;AA2CA,MAAIX,MAAM,GAAGD,KAAb,EAAoB;AAClB,QAAIqB,IAAI,GAAGpB,MAAM,GAAGD,KAApB;AAEA;;AACAsB,IAAAA,OAAO,CAACC,IAAR,CAAa,uBAAb;AAEA,UAAMC,MAAM,GAAG5B,KAAK,CAACT,GAAN,CAAWG,KAAD,IAAW;AAClC,UAAIO,MAAM,CAAC4B,GAAP,CAAWnC,KAAX,KAAqB+B,IAAI,GAAG,CAAhC,EAAmC;AACjCC,QAAAA,OAAO,CAACC,IAAR,CAAajC,KAAK,CAACqB,GAAnB;AAEAU,QAAAA,IAAI,IAAI,CAAR;AACA,eAAO,IAAItC,IAAJ,CAASO,KAAK,CAACqB,GAAf,CAAP;AACD;;AAED,aAAOrB,KAAP;AACD,KATc,CAAf;AAWAgC,IAAAA,OAAO,CAACC,IAAR,CAAa,0GAAb;AACA;;AAEA,WAAOC,MAAP;AACD;;AAED,SAAO5B,KAAP;AACD;AAED;;;;;;;AAKA,SAAS8B,SAAT,CAAmB9B,KAAnB,EAA0B;AACxB,QAAM+B,cAAc,GAAG3C,iBAAiB,EAAxC;AAEA,QAAMkC,MAAM,GAAGtB,KAAK,CAACsB,MAArB;AAEA,QAAMM,MAAM,GAAG,EAAf;AAEA,MAAII,MAAM,GAAG,CAAb;AACA,MAAIC,SAAS,GAAG,CAAhB;;AAEA,SAAOD,MAAM,GAAGV,MAAhB,EAAwB;AACtB,UAAMY,KAAK,GAAGlC,KAAK,CAACkC,KAAN,CAAYF,MAAZ,CAAd;AACA,UAAMG,KAAK,GAAGlD,YAAY,CAAC8C,cAAD,EAAiBG,KAAjB,EAAwB,KAAxB,CAA1B;;AAEA,QAAIC,KAAK,IAAInC,KAAK,CAACgC,MAAM,GAAG,CAAV,CAAL,KAAsB,IAAnC,EAAyC;AACvC,YAAMI,IAAI,GAAGpC,KAAK,CAACkC,KAAN,CAAYD,SAAZ,EAAuBD,MAAM,GAAG,CAAhC,CAAb;;AACA,UAAII,IAAJ,EAAU;AACRR,QAAAA,MAAM,CAACjB,IAAP,CAAY,IAAIxB,IAAJ,CAASiD,IAAT,CAAZ;AACD;;AAED,YAAMC,WAAW,GAAGF,KAAK,CAAC,CAAD,CAAL,CAAS,CAAT,CAApB;AACAP,MAAAA,MAAM,CAACjB,IAAP,CAAY,IAAIxB,IAAJ,CAASkD,WAAT,CAAZ;AAEAL,MAAAA,MAAM,IAAIK,WAAW,CAACf,MAAtB;AACAW,MAAAA,SAAS,GAAGD,MAAZ;AACD,KAXD,MAWO,IAAIG,KAAJ,EAAW;AAChB,YAAM,CAACG,GAAD,EAAMnB,OAAN,IAAiBgB,KAAvB;AAEA,YAAMC,IAAI,GAAGpC,KAAK,CAACkC,KAAN,CAAYD,SAAZ,EAAuBD,MAAvB,CAAb;;AACA,UAAII,IAAJ,EAAU;AACRR,QAAAA,MAAM,CAACjB,IAAP,CAAY,IAAIxB,IAAJ,CAASiD,IAAT,CAAZ;AACD;;AACDR,MAAAA,MAAM,CAACjB,IAAP,CAAY,IAAI2B,GAAJ,CAAQ,GAAGnB,OAAX,CAAZ;AAEAa,MAAAA,MAAM,IAAIb,OAAO,CAAC,CAAD,CAAP,CAAWG,MAArB;AACAW,MAAAA,SAAS,GAAGD,MAAZ;AACD,KAXM,MAWA;AACLA,MAAAA,MAAM,IAAI,CAAV;AACD;AACF;;AACD,QAAMI,IAAI,GAAGpC,KAAK,CAACkC,KAAN,CAAYD,SAAZ,EAAuBD,MAAvB,CAAb;;AACA,MAAII,IAAJ,EAAU;AACRR,IAAAA,MAAM,CAACjB,IAAP,CAAY,IAAIxB,IAAJ,CAASiD,IAAT,CAAZ;AACD,GA3CuB,CA6CxB;AACA;;;AACA,SAAOrC,iBAAiB,CAAC6B,MAAD,CAAxB;AACD;;AAEDW,MAAM,CAACC,OAAP,GAAiBV,SAAjB","sourcesContent":["'use strict';\n\nconst { tokens, matchPattern } = require('./tokens');\n\nconst { Text } = tokens;\n\nfunction getTopLevelTokens() {\n  return Object.keys(tokens)\n    .map(key => tokens[key])\n    .filter(token => token.priority > 0)\n    .sort((a, b) => a.priority - b.priority);\n}\n\nfunction removeExtraCloses(input) {\n  const remove = new Set();\n  const closeSubject = /^<!-- END[^ ]* !?(.+) -->$/;\n\n  let opens = 0;\n  let closes = 0;\n\n  const expectedSubjects = [];\n  // try to find a Close with no corresponding Open\n  input.forEach((token, index) => {\n    if (token.tokenType.startsWith('Open')) {\n      opens += 1;\n\n      expectedSubjects.push(\n        (token.subject && token.subject.path) ||\n        (token.test && (token.test.raw || token.test.path))\n      );\n    } else if (token.tokenType === 'Close') {\n      closes += 1;\n\n      const expectedSubject = expectedSubjects.pop();\n\n      if (!expectedSubject) {\n        remove.add(token);\n      } else {\n        const matches = token.raw.match(closeSubject);\n        if (matches && !expectedSubject.startsWith(matches[1])) {\n          remove.add(token);\n          expectedSubjects.push(expectedSubject);\n        } else {\n          // search for a close within close proximity\n          // that has the expected subject\n          for (let i = index + 1; i < input.length; i += 1) {\n            const tok = input[i];\n            if (tok.tokenType.startsWith('Open')) {\n              break;\n            }\n            if (tok.tokenType === 'Close') {\n              const m = tok.raw.match(closeSubject);\n              if (m && m[1] === expectedSubject) {\n                // found one ahead, so remove the current one\n                remove.add(token);\n                expectedSubjects.push(expectedSubject);\n                break;\n              }\n            }\n          }\n        }\n      }\n    }\n  });\n\n  if (closes > opens) {\n    let diff = closes - opens;\n\n    /* eslint-disable no-console */\n    console.warn('Found extra token(s):');\n\n    const output = input.map((token) => {\n      if (remove.has(token) && diff > 0) {\n        console.warn(token.raw);\n\n        diff -= 1;\n        return new Text(token.raw);\n      }\n\n      return token;\n    });\n\n    console.warn('These tokens will be passed through as text, but you should remove them to prevent issues in the future.');\n    /* eslint-enable no-console */\n\n    return output;\n  }\n\n  return input;\n}\n\n/**\n * Generate an array of tokens describing the template\n * @param {string} input\n * @return {Token[]}\n */\nfunction tokenizer(input) {\n  const topLevelTokens = getTopLevelTokens();\n\n  const length = input.length;\n\n  const output = [];\n\n  let cursor = 0;\n  let lastBreak = 0;\n\n  while (cursor < length) {\n    const slice = input.slice(cursor);\n    const found = matchPattern(topLevelTokens, slice, false);\n\n    if (found && input[cursor - 1] === '\\\\') {\n      const text = input.slice(lastBreak, cursor - 1);\n      if (text) {\n        output.push(new Text(text));\n      }\n\n      const escapedText = found[1][0];\n      output.push(new Text(escapedText));\n\n      cursor += escapedText.length;\n      lastBreak = cursor;\n    } else if (found) {\n      const [Tok, matches] = found;\n\n      const text = input.slice(lastBreak, cursor);\n      if (text) {\n        output.push(new Text(text));\n      }\n      output.push(new Tok(...matches));\n\n      cursor += matches[0].length;\n      lastBreak = cursor;\n    } else {\n      cursor += 1;\n    }\n  }\n  const text = input.slice(lastBreak, cursor);\n  if (text) {\n    output.push(new Text(text));\n  }\n\n  // if there are more closes than opens\n  // intelligently remove extra ones\n  return removeExtraCloses(output);\n}\n\nmodule.exports = tokenizer;\n"],"file":"tokenizer.js"}